import os
import requests
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import mlflow
import mlflow.sklearn

# ========== STEP 1: Ensure dataset exists ==========
csv_path = "data/heart.csv"

# âœ… Verified working dataset source (UCI Heart Disease data)
data_url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/HeartDisease.csv"

if not os.path.exists(csv_path):
    os.makedirs("data", exist_ok=True)
    print("ğŸ“¥ Downloading dataset from:", data_url)
    try:
        response = requests.get(data_url)
        response.raise_for_status()
        with open(csv_path, "wb") as f:
            f.write(response.content)
        print("âœ… heart.csv downloaded successfully.")
    except Exception as e:
        print("âŒ Failed to download dataset:", e)
        raise SystemExit("Dataset download failed â€” stopping pipeline.")

# ========== STEP 2: Load and inspect dataset ==========
try:
    df = pd.read_csv(csv_path)
    print(f"âœ… Dataset loaded. Shape: {df.shape}")
except Exception as e:
    raise SystemExit(f"âŒ Error reading dataset: {e}")

print("\nğŸ“‹ Columns:", df.columns.tolist())
print(df.head())

# ========== STEP 3: Verify / rename target column ==========
if "HeartDisease" in df.columns and "target" not in df.columns:
    df.rename(columns={"HeartDisease": "target"}, inplace=True)
    print("ğŸ” Renamed 'HeartDisease' column to 'target'.")

if "target" not in df.columns:
    raise ValueError(f"âŒ 'target' column not found. Available columns: {df.columns.tolist()}")

# ========== STEP 4: Split data ==========
X = df.drop("target", axis=1)
y = df["target"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"âœ… Data split: {X_train.shape[0]} train / {X_test.shape[0]} test")

# ========== STEP 5: Train model ==========
model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
model.fit(X_train, y_train)
print("âœ… Model training complete.")

# ========== STEP 6: Evaluate model ==========
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

metrics = {
    "accuracy": accuracy_score(y_test, y_pred),
    "precision": precision_score(y_test, y_pred),
    "recall": recall_score(y_test, y_pred),
    "f1": f1_score(y_test, y_pred),
    "auc": roc_auc_score(y_test, y_prob)
}

print("\nğŸ“Š Evaluation Metrics:")
for k, v in metrics.items():
    print(f"{k}: {v:.4f}")

# ========== STEP 7: Log metrics with MLflow ==========
mlflow.set_experiment("heart_experiment")
with mlflow.start_run():
    mlflow.log_params({"model": "RandomForest", "max_depth": 5, "n_estimators": 100})
    mlflow.log_metrics(metrics)
    mlflow.sklearn.log_model(model, "model")

# ========== STEP 8: Save trained model ==========
os.makedirs("models", exist_ok=True)
model_path = "models/heart_model.joblib"
joblib.dump(model, model_path)
print(f"âœ… Model saved at: {model_path}")
