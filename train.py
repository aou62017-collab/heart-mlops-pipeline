import os
import requests
import pandas as pd
import joblib
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# ===== STEP 1: Load dataset =====
csv_path = "data/heart.csv"
data_url = "https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv"

if not os.path.exists(csv_path):
    os.makedirs("data", exist_ok=True)
    print("ðŸ“¥ Downloading dataset from:", data_url)
    response = requests.get(data_url)
    with open(csv_path, "wb") as f:
        f.write(response.content)
    print("âœ… heart.csv downloaded successfully.")

df = pd.read_csv(csv_path)
print(f"âœ… Dataset loaded. Shape: {df.shape}")
print("Columns:", list(df.columns))

# ===== STEP 2: Prepare Data =====
target = "target"
features = [col for col in df.columns if col != target]

X = df[features]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"âœ… Data split: {len(X_train)} train / {len(X_test)} test")

# ===== STEP 3: Define preprocessing + model pipeline =====
numeric_features = X_train.columns.tolist()
numeric_transformer = Pipeline(steps=[("scaler", StandardScaler())])

preprocessor = ColumnTransformer(
    transformers=[("num", numeric_transformer, numeric_features)],
    remainder="drop"
)

pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("model", LogisticRegression(max_iter=1000))
])

# ===== STEP 4: Train =====
mlflow.set_tracking_uri("file:./mlruns")
mlflow.set_experiment("HeartDiseasePrediction")

with mlflow.start_run():
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "auc": roc_auc_score(y_test, y_pred),
    }

    for k, v in metrics.items():
        print(f"{k}: {v:.4f}")
        mlflow.log_metric(k, v)

    mlflow.sklearn.log_model(pipeline, "model")

# ===== STEP 5: Save model =====
os.makedirs("models", exist_ok=True)
joblib.dump(pipeline, "models/heart_model.joblib")
print("âœ… Model saved at models/heart_model.joblib")
